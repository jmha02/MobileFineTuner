#include "gemma_trainer.h"
#include "../graph/gemma_model.h"
#include "../graph/gemma_lora_injector.h"
#include "../graph/safetensors_loader.h"
#include "../core/tokenizer_gemma.h"
#include "../core/lm_loss.h"
#include "../core/ops.h"
#include "../core/memory_manager.h"
#include "../data/wikitext2_dataset.h"
#include "../../opt_ops/sharding/parameter_sharder.h"
#include <iostream>
#include <unordered_map>
#include <memory>
#include <sstream>
#include <filesystem>
#include <fstream>
#include <cstring>
#include <algorithm>

using namespace ops;

namespace {

std::vector<int> parse_layers(const std::string& s) {
    std::vector<int> out;
    std::stringstream ss(s);
    std::string token;
    while (std::getline(ss, token, ',')) {
        if (!token.empty()) {
            out.push_back(std::stoi(token));
        }
    }
    return out;
}

enum class DumpDType { kFloat32, kInt32 };

bool save_npy(const std::string& path,
              const void* data,
              const std::vector<int64_t>& shape,
              DumpDType dtype) {
    std::string descr = (dtype == DumpDType::kFloat32) ? "<f4" : "<i4";
    std::string shape_str = "(";
    for (size_t i = 0; i < shape.size(); ++i) {
        shape_str += std::to_string(shape[i]);
        if (shape.size() == 1) shape_str += ",";
        if (i + 1 < shape.size()) shape_str += ", ";
    }
    shape_str += ")";
    std::string header_dict = "{'descr': '" + descr +
        "', 'fortran_order': False, 'shape': " + shape_str + ", }";

    std::string magic = "\x93NUMPY";
    uint8_t ver_major = 1, ver_minor = 0;
    size_t header_len = header_dict.size() + 1;
    size_t preamble = magic.size() + 2 + 2;
    size_t padding = 16 - ((preamble + header_len) % 16);
    if (padding == 16) padding = 0;
    header_dict += std::string(padding, ' ');
    header_dict.push_back('\n');
    uint16_t header_size_le = static_cast<uint16_t>(header_dict.size());

    std::filesystem::create_directories(std::filesystem::path(path).parent_path());
    std::ofstream out(path, std::ios::binary);
    if (!out) return false;
    out.write(magic.data(), magic.size());
    out.put(static_cast<char>(ver_major));
    out.put(static_cast<char>(ver_minor));
    out.write(reinterpret_cast<const char*>(&header_size_le), sizeof(header_size_le));
    out.write(header_dict.data(), header_dict.size());

    size_t count = 1;
    for (auto d : shape) count *= static_cast<size_t>(d);
    size_t elem_size = 4;
    out.write(reinterpret_cast<const char*>(data), static_cast<std::streamsize>(count * elem_size));
    return true;
}

void save_with_transpose_if_needed(const std::string& path,
                                   const TensorPtr& t,
                                   bool transpose2d = false) {
    auto shape = t->shape();
    std::vector<int64_t> shp(shape.begin(), shape.end());
    const void* data_ptr = t->data<void>();
    std::vector<float> temp;
    DumpDType dt = (t->dtype() == DType::kFloat32) ? DumpDType::kFloat32 : DumpDType::kInt32;
    if (transpose2d && shp.size() == 2 && dt == DumpDType::kFloat32) {
        int64_t rows = shp[0], cols = shp[1];
        temp.resize(static_cast<size_t>(rows * cols));
        const float* src = t->data<float>();
        for (int64_t r = 0; r < rows; ++r) {
            for (int64_t c = 0; c < cols; ++c) {
                temp[static_cast<size_t>(c * rows + r)] = src[static_cast<size_t>(r * cols + c)];
            }
        }
        data_ptr = temp.data();
        shp = {cols, rows};
    }
    save_npy(path, data_ptr, shp, dt);
}

std::vector<float> compute_per_token_nll(const TensorPtr& logits,
                                         const TensorPtr& labels,
                                         int ignore_index) {
    auto shape = logits->shape();  // [B,S,V]
    if (shape.size() != 3) throw std::runtime_error("logits rank must be 3");
    int64_t B = shape[0], S = shape[1], V = shape[2];
    const float* logit_data = logits->data<float>();
    const int32_t* label_data = labels->data<int32_t>();
    std::vector<float> output(static_cast<size_t>(B * (S - 1)), 0.0f);

    for (int64_t b = 0; b < B; ++b) {
        for (int64_t s = 0; s < S - 1; ++s) {  // shift like HF: logits[:-1], labels[1:]
            int64_t label_idx = b * S + (s + 1);
            int label = label_data[label_idx];
            if (label == ignore_index) {
                output[static_cast<size_t>(b * (S - 1) + s)] = 0.0f;
                continue;
            }
            const float* row = logit_data + (b * S + s) * V;
            float maxv = row[0];
            for (int64_t j = 1; j < V; ++j) {
                if (row[j] > maxv) maxv = row[j];
            }
            double sum = 0.0;
            for (int64_t j = 0; j < V; ++j) {
                sum += std::exp(static_cast<double>(row[j] - maxv));
            }
            double logsum = std::log(sum) + static_cast<double>(maxv);
            double nll = logsum - static_cast<double>(row[label]);
            output[static_cast<size_t>(b * (S - 1) + s)] = static_cast<float>(nll);
        }
    }
    return output;
}

// Lightweight npy float32 loader, only for alignment debugging
bool load_npy_float32(const std::string& path,
                      std::vector<int64_t>& shape_out,
                      std::vector<float>& data_out) {
    std::ifstream in(path, std::ios::binary);
    if (!in) return false;
    char magic[7] = {0};
    in.read(magic, 6);
    if (std::string_view(magic, 6) != "\x93NUMPY") return false;
    char ver[2];
    in.read(ver, 2);
    uint16_t header_len = 0;
    in.read(reinterpret_cast<char*>(&header_len), sizeof(header_len));
    std::string header(header_len, '\0');
    in.read(header.data(), header_len);
    if (header.find("<f4") == std::string::npos) return false;
    auto l = header.find('(');
    auto r = header.find(')', l);
    if (l == std::string::npos || r == std::string::npos) return false;
    std::string shape_str = header.substr(l + 1, r - l - 1);
    shape_out.clear();
    std::stringstream ss(shape_str);
    std::string tok;
    while (std::getline(ss, tok, ',')) {
        if (tok.empty()) continue;
        shape_out.push_back(std::stoll(tok));
    }
    size_t count = 1;
    for (auto d : shape_out) count *= static_cast<size_t>(d);
    data_out.resize(count);
    in.read(reinterpret_cast<char*>(data_out.data()), static_cast<std::streamsize>(count * sizeof(float)));
    return in.good();
}

}  // namespace

struct CliOptions {
    std::string model_dir = "gemma-3-270m";
    std::string data_dir = "data/wikitext2/wikitext-2-raw";
    std::string output_dir = "./gemma_lora";
    std::string pretokenized_path;
    std::string pretokenized_meta;
    std::string align_dump_dir;
    std::string align_layers = "0,1,17";
    bool align_dump_grads = true;
    bool align_do_step = true;
    bool align_disable_debug = false;
    bool align_no_retain_grad = false;
    // Optional: Override LoRA A weights from PT dump in alignment mode
    std::string align_pt_weights_dir;
    // Optional: Numerical gradient check on layer0 attn_out_raw using finite differences in alignment mode
    bool align_numeric_attn = false;
    float align_numeric_eps = 1e-3f;
    int align_numeric_count = 4;  // Number of elements to check per target
    std::string align_numeric_targets = "attn_out_raw_l0";
    std::string target_mode = "full";
    std::string lora_targets_override;  // Comma-separated, overrides target_mode default list when non-empty
    // Parameter sharding
    bool shard_enable = false;
    std::string shard_dir = "/tmp/gemma_param_shard";
    int shard_budget_mb = 512;
    bool shard_fp16_disk = true;

    int epochs = 1;
    int max_steps = -1;
    int seq_len = 256;
    int batch = 4;
    int grad_accum = 1;
    float learning_rate = 2e-4f;
    float warmup_ratio = 0.03f;
    float max_grad_norm = 1.0f;
    float data_fraction = 1.0f;
    float weight_decay = 0.0f;
    std::string loss_reduction = "mean";  // Can be changed to sum_debug for alignment debugging
    bool dump_embedding = false;
    int dump_embedding_step = 1;
    std::string dump_embedding_dir = "./debug";
    int preview_tokens = 0;

    // Energy-aware throttling
    int pm_interval = 0;
    float pm_batt_thresh = 20.0f;
    float pm_temp_thresh = 42.0f;
    float pm_fb_high = 2.0f, pm_fb_low = 0.5f;
    float pm_ft_high = 2.0f, pm_ft_low = 0.5f;
    float pm_manual_batt = 100.0f;
    float pm_manual_temp = 30.0f;
    bool pm_enable_batt = true;
    bool pm_enable_temp = true;
    std::string pm_schedule;
};

CliOptions parse_cli(int argc, char** argv) {
    CliOptions opts;
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        auto get_val = [&](const std::string& key) -> std::string {
            auto pos = arg.find('=');
            if (pos != std::string::npos) return arg.substr(pos + 1);
            if (i + 1 < argc) return argv[++i];
            return "";
        };
        if (arg.rfind("--model_dir", 0) == 0) {
            opts.model_dir = get_val("--model_dir");
        } else if (arg.rfind("--data_dir", 0) == 0) {
            opts.data_dir = get_val("--data_dir");
        } else if (arg.rfind("--pretokenized_path", 0) == 0) {
            opts.pretokenized_path = get_val("--pretokenized_path");
        } else if (arg.rfind("--pretokenized_meta", 0) == 0) {
            opts.pretokenized_meta = get_val("--pretokenized_meta");
        } else if (arg.rfind("--align_dump_dir", 0) == 0) {
            opts.align_dump_dir = get_val("--align_dump_dir");
        } else if (arg.rfind("--align_layers", 0) == 0) {
            opts.align_layers = get_val("--align_layers");
        } else if (arg.rfind("--align_dump_grads", 0) == 0) {
            auto v = get_val("--align_dump_grads");
            opts.align_dump_grads = (v != "0" && v != "false" && v != "False");
        } else if (arg.rfind("--align_do_step", 0) == 0) {
            auto v = get_val("--align_do_step");
            opts.align_do_step = (v != "0" && v != "false" && v != "False");
        } else if (arg.rfind("--align_disable_debug", 0) == 0) {
            auto v = get_val("--align_disable_debug");
            opts.align_disable_debug = (v != "0" && v != "false" && v != "False");
        } else if (arg.rfind("--align_no_retain_grad", 0) == 0) {
            auto v = get_val("--align_no_retain_grad");
            opts.align_no_retain_grad = (v != "0" && v != "false" && v != "False");
        } else if (arg.rfind("--align_pt_weights_dir", 0) == 0) {
            opts.align_pt_weights_dir = get_val("--align_pt_weights_dir");
        } else if (arg.rfind("--output_dir", 0) == 0) {
            opts.output_dir = get_val("--output_dir");
        } else if (arg.rfind("--targets", 0) == 0) {
            opts.target_mode = get_val("--targets");
        } else if (arg.rfind("--lora_targets", 0) == 0) {
            opts.lora_targets_override = get_val("--lora_targets");  // e.g., "q_proj,k_proj"
        } else if (arg.rfind("--epochs", 0) == 0) {
            opts.epochs = std::stoi(get_val("--epochs"));
        } else if (arg.rfind("--max_steps", 0) == 0) {
            opts.max_steps = std::stoi(get_val("--max_steps"));
        } else if (arg.rfind("--seq_len", 0) == 0) {
            opts.seq_len = std::stoi(get_val("--seq_len"));
        } else if (arg.rfind("--batch", 0) == 0) {
            opts.batch = std::stoi(get_val("--batch"));
        } else if (arg.rfind("--grad_accum", 0) == 0) {
            opts.grad_accum = std::stoi(get_val("--grad_accum"));
        } else if (arg.rfind("--lr", 0) == 0) {
            opts.learning_rate = std::stof(get_val("--lr"));
        } else if (arg.rfind("--warmup_ratio", 0) == 0) {
            opts.warmup_ratio = std::stof(get_val("--warmup_ratio"));
        } else if (arg.rfind("--max_grad_norm", 0) == 0) {
            opts.max_grad_norm = std::stof(get_val("--max_grad_norm"));
        } else if (arg.rfind("--weight_decay", 0) == 0) {
            opts.weight_decay = std::stof(get_val("--weight_decay"));
        } else if (arg.rfind("--loss_reduction", 0) == 0) {
            opts.loss_reduction = get_val("--loss_reduction");
        } else if (arg.rfind("--data_fraction", 0) == 0) {
            opts.data_fraction = std::stof(get_val("--data_fraction"));
        } else if (arg.rfind("--dump_embedding_step", 0) == 0) {
            opts.dump_embedding_step = std::stoi(get_val("--dump_embedding_step"));
        } else if (arg.rfind("--dump_embedding_dir", 0) == 0) {
            opts.dump_embedding_dir = get_val("--dump_embedding_dir");
        } else if (arg.rfind("--dump_embedding", 0) == 0) {
            auto val = get_val("--dump_embedding");
            opts.dump_embedding = (val == "1" || val == "true" || val == "True");
        } else if (arg.rfind("--preview_tokens", 0) == 0) {
            opts.preview_tokens = std::stoi(get_val("--preview_tokens"));
        } else if (arg.rfind("--align_pt_weights_dir", 0) == 0) {
            opts.align_pt_weights_dir = get_val("--align_pt_weights_dir");
        } else if (arg.rfind("--align_numeric_attn", 0) == 0) {
            auto v = get_val("--align_numeric_attn");
            opts.align_numeric_attn = (v != "0" && v != "false" && v != "False");
        } else if (arg.rfind("--align_numeric_eps", 0) == 0) {
            opts.align_numeric_eps = std::stof(get_val("--align_numeric_eps"));
        } else if (arg.rfind("--align_numeric_count", 0) == 0) {
            opts.align_numeric_count = std::stoi(get_val("--align_numeric_count"));
        } else if (arg.rfind("--align_numeric_targets", 0) == 0) {
            opts.align_numeric_targets = get_val("--align_numeric_targets");
        } else if (arg.rfind("--shard_enable", 0) == 0) {
            opts.shard_enable = true;
        } else if (arg.rfind("--shard_dir", 0) == 0) {
            opts.shard_dir = get_val("--shard_dir");
        } else if (arg.rfind("--shard_budget_mb", 0) == 0) {
            opts.shard_budget_mb = std::stoi(get_val("--shard_budget_mb"));
        } else if (arg.rfind("--shard_fp16_disk", 0) == 0) {
            opts.shard_fp16_disk = (std::stoi(get_val("--shard_fp16_disk")) != 0);
        } else if (arg.rfind("--pm_interval", 0) == 0) {
            opts.pm_interval = std::stoi(get_val("--pm_interval"));
        } else if (arg.rfind("--pm_batt_thresh", 0) == 0) {
            opts.pm_batt_thresh = std::stof(get_val("--pm_batt_thresh"));
        } else if (arg.rfind("--pm_temp_thresh", 0) == 0) {
            opts.pm_temp_thresh = std::stof(get_val("--pm_temp_thresh"));
        } else if (arg.rfind("--pm_fb_high", 0) == 0) {
            opts.pm_fb_high = std::stof(get_val("--pm_fb_high"));
        } else if (arg.rfind("--pm_fb_low", 0) == 0) {
            opts.pm_fb_low = std::stof(get_val("--pm_fb_low"));
        } else if (arg.rfind("--pm_ft_high", 0) == 0) {
            opts.pm_ft_high = std::stof(get_val("--pm_ft_high"));
        } else if (arg.rfind("--pm_ft_low", 0) == 0) {
            opts.pm_ft_low = std::stof(get_val("--pm_ft_low"));
        } else if (arg.rfind("--pm_manual_batt", 0) == 0) {
            opts.pm_manual_batt = std::stof(get_val("--pm_manual_batt"));
        } else if (arg.rfind("--pm_manual_temp", 0) == 0) {
            opts.pm_manual_temp = std::stof(get_val("--pm_manual_temp"));
        } else if (arg.rfind("--pm_disable_batt", 0) == 0) {
            auto v = get_val("--pm_disable_batt");
            opts.pm_enable_batt = !(v == "1" || v == "true" || v == "True");
        } else if (arg.rfind("--pm_disable_temp", 0) == 0) {
            auto v = get_val("--pm_disable_temp");
            opts.pm_enable_temp = !(v == "1" || v == "true" || v == "True");
        } else if (arg.rfind("--pm_schedule", 0) == 0) {
            opts.pm_schedule = get_val("--pm_schedule");
        }
    }
    return opts;
}

int main(int argc, char** argv) {
    try {
        auto cli = parse_cli(argc, argv);

        std::cout << "========== Gemma LoRA Fine-tuning ==========\n" << std::endl;
        std::cout << "[INFO] model_dir=" << cli.model_dir << std::endl;
        if (!cli.pretokenized_path.empty()) {
            std::cout << "[INFO] pretokenized_path=" << cli.pretokenized_path << std::endl;
            if (!cli.pretokenized_meta.empty()) {
                std::cout << "[INFO] pretokenized_meta=" << cli.pretokenized_meta << std::endl;
            }
        } else {
            std::cout << "[INFO] data_dir=" << cli.data_dir << std::endl;
        }
        std::cout << "[Energy] pm_interval=" << cli.pm_interval
                  << " batt_th=" << cli.pm_batt_thresh
                  << " temp_th=" << cli.pm_temp_thresh
                  << " fb_hi/lo=" << cli.pm_fb_high << "/" << cli.pm_fb_low
                  << " ft_hi/lo=" << cli.pm_ft_high << "/" << cli.pm_ft_low
                  << " manual_batt=" << cli.pm_manual_batt
                  << " manual_temp=" << cli.pm_manual_temp
                  << " schedule=\"" << cli.pm_schedule << "\""
                  << std::endl;
        std::cout << "[Shard] enable=" << (cli.shard_enable ? "ON" : "OFF")
                  << " dir=" << cli.shard_dir
                  << " budget_mb=" << cli.shard_budget_mb
                  << " disk_fp16=" << (cli.shard_fp16_disk ? "ON" : "OFF")
                  << std::endl;

        // 1. Load config & weights
        auto cfg = GemmaTextConfig::from_pretrained(cli.model_dir);
        GemmaModel model(cfg);
        if (cli.align_no_retain_grad) {
            model.set_debug_retain_grads(false);
        }

        SafeTensorsReader reader(cli.model_dir + "/model.safetensors");
        reader.parse_header();
        auto mapping = GemmaKeyMapper::generate_gemma_mapping(cfg.num_hidden_layers);
        SafeTensorsLoadOptions load_opts;
        load_opts.verbose = false;
        auto tensors = reader.load_tensors_mapped(mapping, load_opts);
        for (auto& kv : tensors) {
            model.assign_weight(kv.first, kv.second);
        }
        std::cout << "Gemma weights loaded\n";

        // Parameter sharding (optional)
        std::unique_ptr<sharding::ParameterSharder> sharder;
        size_t max_param_bytes = 0;
        auto tensor_bytes = [](const TensorPtr& t) -> size_t {
            if (!t) return 0;
            size_t elems = 1;
            for (auto d : t->shape()) elems *= static_cast<size_t>(d);
            size_t elem_size = (t->dtype() == DType::kFloat16) ? sizeof(uint16_t) : sizeof(float);
            return elems * elem_size;
        };
        // Pre-scan maximum parameter size (to ensure budget is not lower than single param size)
        {
            max_param_bytes = std::max(max_param_bytes, tensor_bytes(model.embed_weight_ref()));
            max_param_bytes = std::max(max_param_bytes, tensor_bytes(model.norm_weight_ref()));
            max_param_bytes = std::max(max_param_bytes, tensor_bytes(model.lm_head_weight_ref()));
            for (int li = 0; li < cfg.num_hidden_layers; ++li) {
                auto& blk = model.get_block(li);
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.input_layernorm_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.post_attention_layernorm_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.pre_feedforward_layernorm_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.post_feedforward_layernorm_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.q_proj_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.k_proj_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.v_proj_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.o_proj_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.q_norm_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.k_norm_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.gate_proj_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.up_proj_weight));
                max_param_bytes = std::max(max_param_bytes, tensor_bytes(blk.down_proj_weight));
            }
        }
        if (cli.shard_enable) {
            sharding::ShardConfig sc;
            sc.offload_dir = cli.shard_dir;
            size_t requested_budget = static_cast<size_t>(cli.shard_budget_mb) * 1024ull * 1024ull;
            size_t final_budget = std::max(requested_budget, max_param_bytes);
            if (final_budget != requested_budget) {
                std::cout << "[Shard] Adjust budget to fit largest parameter: "
                          << (final_budget / 1024.0 / 1024.0) << " MB\n";
            }
            sc.max_resident_bytes = final_budget;
            sc.quantize_fp16_on_disk = cli.shard_fp16_disk;
            sharder = std::make_unique<sharding::ParameterSharder>(sc);
            model.set_parameter_sharder(sharder.get());

            auto reg = [&](const std::string& name, TensorPtr& ref) {
                sharder->register_parameter(name, ref, false, &ref);
            };
            reg("embed_tokens.weight", model.embed_weight_ref());
            reg("norm.weight", model.norm_weight_ref());
            reg("lm_head.weight", model.lm_head_weight_ref());
            for (int li = 0; li < cfg.num_hidden_layers; ++li) {
                auto& blk = model.get_block(li);
                const std::string p = "layers." + std::to_string(li) + ".";
                reg(p + "input_layernorm.weight", blk.input_layernorm_weight);
                reg(p + "post_attention_layernorm.weight", blk.post_attention_layernorm_weight);
                reg(p + "pre_feedforward_layernorm.weight", blk.pre_feedforward_layernorm_weight);
                reg(p + "post_feedforward_layernorm.weight", blk.post_feedforward_layernorm_weight);
                reg(p + "self_attn.q_proj.weight", blk.q_proj_weight);
                reg(p + "self_attn.k_proj.weight", blk.k_proj_weight);
                reg(p + "self_attn.v_proj.weight", blk.v_proj_weight);
                reg(p + "self_attn.o_proj.weight", blk.o_proj_weight);
                reg(p + "self_attn.q_norm.weight", blk.q_norm_weight);
                reg(p + "self_attn.k_norm.weight", blk.k_norm_weight);
                reg(p + "mlp.gate_proj.weight", blk.gate_proj_weight);
                reg(p + "mlp.up_proj.weight", blk.up_proj_weight);
                reg(p + "mlp.down_proj.weight", blk.down_proj_weight);
            }
            tensors.clear();
            tensors.rehash(0);
            MemoryManager::instance().force_cleanup();
        }

        // 2. Tokenizer (optional: placeholder in pre-tokenized mode)
        std::unique_ptr<GemmaTokenizer> tokenizer;
        std::function<std::vector<int32_t>(const std::string&)> encode_fn;
        if (cli.pretokenized_path.empty()) {
            auto tok_cfg = GemmaTokenizerConfig::from_pretrained(cli.model_dir);
            tokenizer = std::make_unique<GemmaTokenizer>(tok_cfg);
            tokenizer->load();

            encode_fn = [tok = tokenizer.get()](const std::string& text) {
                auto ids = tok->encode(text, false, 0, false);
                return std::vector<int32_t>(ids.begin(), ids.end());
            };
        } else {
            encode_fn = [](const std::string&) {
                return std::vector<int32_t>{};
            };
        }

        // 3. LoRA injection
        GemmaLoraSpec lora_spec = GemmaLoraSpec::full_attn_mlp();
        if (cli.target_mode == "light") {
            lora_spec = GemmaLoraSpec::attention_light();
        } else if (cli.target_mode == "attn") {
            lora_spec = GemmaLoraSpec::attention_only();
        }
        if (!cli.lora_targets_override.empty()) {
            // Parse comma-separated targets, overriding default module list; used for alignment/debugging with single or partial LoRA modules.
            lora_spec.target_modules.clear();
            std::stringstream ss(cli.lora_targets_override);
            std::string tok;
            while (std::getline(ss, tok, ',')) {
                if (!tok.empty()) lora_spec.target_modules.push_back(tok);
            }
        }
        if (!cli.align_dump_dir.empty()) {
            lora_spec.dropout = 0.0f;  // Disable dropout during alignment
        }
        GemmaLoraInjector injector;
        if (sharder) {
            auto req = [&](const std::string& name) { sharder->require(name); };
            req("embed_tokens.weight");
            req("norm.weight");
            req("lm_head.weight");
            for (int li = 0; li < cfg.num_hidden_layers; ++li) {
                const std::string p = "layers." + std::to_string(li) + ".";
                req(p + "input_layernorm.weight");
                req(p + "post_attention_layernorm.weight");
                req(p + "pre_feedforward_layernorm.weight");
                req(p + "post_feedforward_layernorm.weight");
                req(p + "self_attn.q_proj.weight");
                req(p + "self_attn.k_proj.weight");
                req(p + "self_attn.v_proj.weight");
                req(p + "self_attn.o_proj.weight");
                req(p + "self_attn.q_norm.weight");
                req(p + "self_attn.k_norm.weight");
                req(p + "mlp.gate_proj.weight");
                req(p + "mlp.up_proj.weight");
                req(p + "mlp.down_proj.weight");
            }
        }
        injector.inject(model, lora_spec);
        injector.print_info();
        if (sharder) {
            // After LoRA injection, offload resident parameters, load on-demand later
            sharder->offload_all();
        }

        // Optional: Override LoRA A initial weights with PT dump in alignment mode (verify random stream differences)
        if (!cli.align_pt_weights_dir.empty()) {
            auto load_lora_a = [&](LoRALinear* lora) {
                if (!lora) return;
                for (auto& pair : lora->debug_params()) {
                    if (pair.first.find("lora_A") == std::string::npos) continue;
                    std::string fname = cli.align_pt_weights_dir + "/weights_after_step/base_model_model_model_" + pair.first + ".npy";
                    if (!std::filesystem::exists(fname)) continue;
                    std::vector<int64_t> shp;
                    std::vector<float> data;
                    if (!load_npy_float32(fname, shp, data)) {
                        std::cerr << "[Align] Failed to load " << fname << std::endl;
                        continue;
                    }
                    auto expect = pair.second->shape();
                    size_t expect_count = 1;
                    bool shape_ok = (shp.size() == expect.size());
                    for (size_t i = 0; i < expect.size(); ++i) {
                        expect_count *= static_cast<size_t>(expect[i]);
                        if (!shape_ok || shp[i] != expect[i]) shape_ok = false;
                    }
                    if (!shape_ok || expect_count != data.size()) {
                        std::cerr << "[Align] Shape mismatch for " << fname << std::endl;
                        continue;
                    }
                    std::memcpy(pair.second->data<float>(), data.data(), expect_count * sizeof(float));
                    std::cout << "[Align] Loaded PT LoRA A from " << fname << std::endl;
                }
            };
            for (int l = 0; l < cfg.num_hidden_layers; ++l) {
                auto& blk = model.get_block(l);
                load_lora_a(blk.q_proj_lora.get());
                load_lora_a(blk.k_proj_lora.get());
                load_lora_a(blk.v_proj_lora.get());
                load_lora_a(blk.o_proj_lora.get());
            }
        }

        // 4. Dataset
        WT2Config data_cfg;
        data_cfg.seq_len = cli.seq_len;
        data_cfg.data_fraction = cli.data_fraction;
        if (!cli.align_dump_dir.empty()) {
            data_cfg.shuffle_train = false;
        }
        if (cli.pretokenized_path.empty()) {
            data_cfg.train_path = cli.data_dir + "/wiki.train.raw";
            data_cfg.valid_path = cli.data_dir + "/wiki.valid.raw";
            data_cfg.eos_id = tokenizer->get_eos_token_id();
            int pad_id = tokenizer->get_pad_token_id();
            data_cfg.pad_id = (pad_id >= 0) ? pad_id : data_cfg.eos_id;
        } else {
            data_cfg.pretokenized_path = cli.pretokenized_path;
            data_cfg.pretokenized_meta = cli.pretokenized_meta;
            data_cfg.eos_id = -1;
            data_cfg.pad_id = 0;
            data_cfg.streaming_mode = false;
            data_cfg.insert_eos_between_lines = true;
        }

        WikiText2Dataset train_data(data_cfg, encode_fn);
        train_data.load(Split::Train);
        WikiText2Dataset eval_data(data_cfg, encode_fn);
        eval_data.load(Split::Valid);

        std::cout << "Train sequences: " << train_data.num_sequences()
                  << ", Eval sequences: " << eval_data.num_sequences() << std::endl;

        // Alignment mode: Run only a small batch forward and dump intermediate activations/loss
        if (!cli.align_dump_dir.empty()) {
            auto layers = parse_layers(cli.align_layers);
            bool dump_all_layers = layers.empty();
            std::vector<int> target_layers = dump_all_layers ? std::vector<int>{0, 1, 17} : layers;
            std::sort(target_layers.begin(), target_layers.end());
            std::cout << "[Align] align_layers="
                      << (cli.align_layers.empty() ? "(empty)" : cli.align_layers)
                      << " parsed=";
            if (dump_all_layers) {
                std::cout << "ALL";
            } else {
                for (size_t i = 0; i < target_layers.size(); ++i) {
                    if (i) std::cout << ",";
                    std::cout << target_layers[i];
                }
            }
            std::cout << std::endl;

            if (cli.align_disable_debug) {
                std::cout << "[Align] debug dump disabled (no intermediate hooks/retain)" << std::endl;
            } else {
                model.enable_debug_dump(cli.align_dump_dir, layers);
            }
            auto batch = train_data.next_batch(1, false);
            // Dump exact inputs to ensure PT baseline can reuse identical tokens/mask/labels
            {
                if (batch.input_ids) {
                    save_npy(cli.align_dump_dir + "/input_ids.npy",
                             batch.input_ids->data<int32_t>(),
                             batch.input_ids->shape(),
                             DumpDType::kInt32);
                }
                if (batch.attention_mask) {
                    save_npy(cli.align_dump_dir + "/attention_mask.npy",
                             batch.attention_mask->data<float>(),
                             batch.attention_mask->shape(),
                             DumpDType::kFloat32);
                }
                if (batch.labels) {
                    save_npy(cli.align_dump_dir + "/labels.npy",
                             batch.labels->data<int32_t>(),
                             batch.labels->shape(),
                             DumpDType::kInt32);
                }
                // dump layer norm weights for selected layers to aid weight parity checks
                for (int layer : target_layers) {
                    model.dump_layer_norm_weights(layer, cli.align_dump_dir);
                }
            }
            auto logits = model.forward(batch.input_ids, batch.attention_mask);
            logits->set_requires_grad(true);  // Enable dumping dlogits during alignment
            logits->retain_grad();
            auto loss = lm_cross_entropy(logits, batch.labels, -100, cli.loss_reduction);

            auto per_token = compute_per_token_nll(logits, batch.labels, -100);
            int64_t S = batch.labels->shape()[1];
            save_npy(cli.align_dump_dir + "/per_token_nll.npy",
                     per_token.data(),
                     {batch.labels->shape()[0], S - 1},
                     DumpDType::kFloat32);
            // loss_scalar directly uses lm_cross_entropy output (with reduction), consistent with PT baseline.
            float loss_val = loss->data<float>()[0];
            save_npy(cli.align_dump_dir + "/loss_scalar.npy", &loss_val, {1}, DumpDType::kFloat32);

            if (cli.align_dump_grads) {
                loss->backward();
                float base_loss = loss_val;
                // Dump LoRA parameter gradients for selected layers
                auto dump_lora = [&](const TensorPtr& t, const std::string& name) {
                    if (!t || !t->grad()) return;
                    auto grad = t->grad();
                    auto shape = grad->shape();
                    std::vector<int64_t> shp(shape.begin(), shape.end());
                    const float* data = grad->data<float>();
                    if (shp.size() == 3 && shp[0] == 1) {
                        shp.erase(shp.begin());  // squeeze batch dim
                    }
                    save_npy(cli.align_dump_dir + "/grads/" + name + ".npy",
                             data,
                             shp,
                             DumpDType::kFloat32);
                };

                for (int layer : target_layers) {
                    auto& blk = model.get_block(layer);
                    for (auto pair : blk.q_proj_lora->debug_params()) dump_lora(pair.second, "base_model_model_model_" + pair.first);
                    for (auto pair : blk.o_proj_lora->debug_params()) dump_lora(pair.second, "base_model_model_model_" + pair.first);
                }

                // Dump logits grad
                if (logits->grad()) {
                    save_npy(cli.align_dump_dir + "/dlogits.npy",
                             logits->grad()->data<float>(),
                             logits->grad()->shape(),
                             DumpDType::kFloat32);
                }
                if (!cli.align_disable_debug) {
                    // Dump intermediate hidden gradients
                    auto debug_map = model.debug_tensors();
                    auto dump_grad = [&](const std::string& key) {
                        auto it = debug_map.find(key);
                        if (it == debug_map.end()) return;
                        auto t = it->second;
                        if (!t || !t->grad()) return;
                        std::vector<int64_t> shp = t->grad()->shape();
                        if (!shp.empty() && shp[0] == 1) {
                            shp.erase(shp.begin());  // squeeze batch dim when it's 1
                        }
                        save_npy(cli.align_dump_dir + "/grads/" + key + ".npy",
                                 t->grad()->data<float>(),
                                 shp,
                                 DumpDType::kFloat32);
                    };
                    dump_grad("hidden_states_emb");
                    const std::vector<std::string> attn_names = {
                        "hidden_before_attn",
                        "hidden_after_attn",
                        "hidden_after_mlp",
                        "hidden_after_attn_norm",
                        "hidden_after_mlp_norm",
                        "q_proj_out",
                        "k_proj_out",
                        "v_proj_out",
                        "q_norm_out",
                        "k_norm_out",
                        "q_norm_out_pre_rope",
                        "k_norm_out_pre_rope",
                        "q_rotary_out",
                        "k_rotary_out",
                        "attn_context",
                        "attn_scores",
                        "attn_probs",
                        "attn_out_raw"};
                    const std::vector<std::string> mlp_names = {
                        "hidden_before_mlp_norm",
                        "gate_proj_out",
                        "gate_act",
                        "up_proj_out",
                        "mlp_prod",
                        "down_proj_out"};
                    for (int layer : target_layers) {
                        for (const auto& base : attn_names) {
                            dump_grad(base + "_l" + std::to_string(layer));
                        }
                        for (const auto& base : mlp_names) {
                            dump_grad(base + "_l" + std::to_string(layer));
                        }
                    }

                    // Analytical gradient export: dMat/dQ/dK/dV (explicit calculation per layer, saved to grads/analytical_*)
                    {
                        auto debug_map_eval = model.debug_tensors();
                        auto fetch = [&](const std::string& key) -> TensorPtr {
                            auto it = debug_map_eval.find(key);
                            if (it == debug_map_eval.end()) return nullptr;
                            return it->second;
                        };
                        const float qk_scale = std::pow(model.config().query_pre_attn_scalar, -0.5f);
                        for (int layer : target_layers) {
                            const std::string L = std::to_string(layer);
                            auto scores = fetch("attn_scores_l" + L);     // [B,H,S,S]
                            auto probs  = fetch("attn_probs_l"  + L);     // [B,H,S,S]
                            auto q      = fetch("q_rotary_out_l" + L);    // [B,H,S,D]
                            auto k_in   = fetch("k_rotary_out_l" + L);    // [B,kvH,S,D]
                            auto ctx    = fetch("attn_context_l" + L);    // [B,S,H*D]
                            if (!scores || !scores->grad() || !probs || !q || !k_in) continue;

                            // dMat = dScores * qk_scale
                            auto dScores = scores->grad();
                            auto dMat = mul(dScores, qk_scale);           // [B,H,S,S]
                            // Save dMat
                            {
                                std::vector<int64_t> shp = dMat->shape();
                                if (!shp.empty() && shp[0] == 1) shp.erase(shp.begin());
                                save_npy(cli.align_dump_dir + "/grads/attn_dmat_l" + L + ".npy",
                                         dMat->data<float>(), shp, DumpDType::kFloat32);
                            }

                            // k_full: repeat kv heads -> H
                            int H = model.config().num_attention_heads;
                            int kvH = model.config().num_key_value_heads;
                            int repeat_factor = std::max(1, H / std::max(1, kvH));
                            auto k_full = repeat_kv_heads(k_in, repeat_factor);   // [B,H,S,D]

                            // dQ_heads = dMat @ k_full
                            auto dQ_heads = matmul(dMat, k_full);                 // [B,H,S,D]
                            {
                                std::vector<int64_t> shp = dQ_heads->shape();
                                if (!shp.empty() && shp[0] == 1) shp.erase(shp.begin());
                                save_npy(cli.align_dump_dir + "/grads/analytical_dq_heads_l" + L + ".npy",
                                         dQ_heads->data<float>(), shp, DumpDType::kFloat32);
                            }

                            // dK_heads = dMat^T @ q
                            auto dK_heads = matmul(transpose(dMat, -2, -1), q);  // [B,H,S,D]
                            {
                                std::vector<int64_t> shp = dK_heads->shape();
                                if (!shp.empty() && shp[0] == 1) shp.erase(shp.begin());
                                save_npy(cli.align_dump_dir + "/grads/analytical_dk_heads_l" + L + ".npy",
                                         dK_heads->data<float>(), shp, DumpDType::kFloat32);
                            }

                            // dV_heads = probs^T @ G_context (restore by heads)
                            if (ctx && ctx->grad()) {
                                auto G = ctx->grad();                            // [B,S,H*D]
                                const auto& gshape = G->shape();
                                if (gshape.size() == 3) {
                                    int64_t B = gshape[0], S = gshape[1];
                                    int64_t hidden = gshape[2];
                                    int64_t D = model.config().head_dim;
                                    int64_t Hcfg = model.config().num_attention_heads;
                                    if (hidden == Hcfg * D) {
                                        auto G_heads = permute(reshape(G, {B, S, Hcfg, D}), {0, 2, 1, 3}); // [B,H,S,D]
                                        auto dV_heads = matmul(transpose(probs, -2, -1), G_heads);         // [B,H,S,D]
                                        std::vector<int64_t> shp = dV_heads->shape();
                                        if (!shp.empty() && shp[0] == 1) shp.erase(shp.begin());
                                        save_npy(cli.align_dump_dir + "/grads/analytical_dv_heads_l" + L + ".npy",
                                                 dV_heads->data<float>(), shp, DumpDType::kFloat32);
                                    }
                                }
                            }
                        }
                    }

                    // Numerical gradient check: finite differences on specified targets
                    if (cli.align_numeric_attn) {
                        auto debug_map_base = model.debug_tensors();  // Baseline forward's grad
                        std::stringstream ss(cli.align_numeric_targets);
                        std::string target;
                        while (std::getline(ss, target, ',')) {
                            if (target.empty()) continue;
                            std::vector<float> numeric(cli.align_numeric_count, 0.0f);
                            std::vector<float> analytic(cli.align_numeric_count, 0.0f);
                            TensorPtr tgt = nullptr;
                            auto it = debug_map_base.find(target);
                            if (it != debug_map_base.end()) tgt = it->second;
                            if (tgt && tgt->grad()) {
                                const float* gdata = tgt->grad()->data<float>();
                                for (int i = 0; i < cli.align_numeric_count && i < tgt->numel(); ++i) {
                                    analytic[i] = gdata[i];
                                }
                            }
                            for (int i = 0; i < cli.align_numeric_count; ++i) {
                                model.set_numeric_perturb(true, target, i, cli.align_numeric_eps);
                                auto logits_eps = model.forward(batch.input_ids, batch.attention_mask);
                                auto loss_eps = lm_cross_entropy(logits_eps, batch.labels, -100, cli.loss_reduction);
                                float loss_eps_val = loss_eps->data<float>()[0];
                                numeric[i] = (loss_eps_val - base_loss) / cli.align_numeric_eps;
                                model.set_numeric_perturb(false, "", -1, cli.align_numeric_eps);
                            }
                            save_npy(cli.align_dump_dir + "/numeric/" + target + "_numeric_grad.npy",
                                     numeric.data(),
                                     {static_cast<int64_t>(numeric.size())},
                                     DumpDType::kFloat32);
                            save_npy(cli.align_dump_dir + "/numeric/" + target + "_analytic_grad.npy",
                                     analytic.data(),
                                     {static_cast<int64_t>(analytic.size())},
                                     DumpDType::kFloat32);
                        }
                    }
                }

                if (cli.align_do_step) {
                    // Single-step AdamW (wd=0), only for LoRA parameters
                    AdamConfig acfg;
                    acfg.learning_rate = cli.learning_rate;
                    acfg.beta1 = 0.9f;
                    acfg.beta2 = 0.999f;
                    acfg.epsilon = 1e-8f;
                    acfg.weight_decay = 0.0f;
                    Adam opt(acfg);
                    auto params_vec = injector.get_trainable_params();
                    std::vector<TensorPtr> grads_vec;
                    grads_vec.reserve(params_vec.size());
                    for (const auto& p : params_vec) {
                        grads_vec.push_back(p->grad());
                    }
                    opt.step(params_vec, grads_vec);
                    // Dump updated parameters
                    for (int layer : target_layers) {
                        auto& blk = model.get_block(layer);
                        for (auto pair : blk.q_proj_lora->debug_params()) {
                            auto t = pair.second;
                            auto shape = t->shape();
                            std::vector<int64_t> shp(shape.begin(), shape.end());
                            const float* data = t->data<float>();
                            if (shp.size() == 3 && shp[0] == 1) {
                                shp.erase(shp.begin());
                            }
                            save_npy(cli.align_dump_dir + "/weights_after_step/base_model_model_model_" + pair.first + ".npy",
                                     data,
                                     shp,
                                     DumpDType::kFloat32);
                        }
                        for (auto pair : blk.o_proj_lora->debug_params()) {
                            auto t = pair.second;
                            auto shape = t->shape();
                            std::vector<int64_t> shp(shape.begin(), shape.end());
                            const float* data = t->data<float>();
                            if (shp.size() == 3 && shp[0] == 1) {
                                shp.erase(shp.begin());
                            }
                            save_npy(cli.align_dump_dir + "/weights_after_step/base_model_model_model_" + pair.first + ".npy",
                                     data,
                                     shp,
                                     DumpDType::kFloat32);
                        }
                    }
                }
            }

            std::cout << "[AlignDump] wrote activations and loss to " << cli.align_dump_dir << std::endl;
            return 0;
        }

        if (cli.preview_tokens > 0) {
            auto head = train_data.peek_tokens(static_cast<size_t>(cli.preview_tokens));
            std::cout << "First " << head.size() << " train tokens: [";
            for (size_t i = 0; i < head.size(); ++i) {
                std::cout << head[i];
                if (i + 1 < head.size()) std::cout << ", ";
            }
            std::cout << "]" << std::endl;
        }

        // 5. Trainer
        GemmaTrainerConfig trainer_cfg;
        trainer_cfg.learning_rate = cli.learning_rate;
        trainer_cfg.num_epochs = cli.epochs;
        trainer_cfg.micro_batch_size = std::max(1, cli.batch);
        trainer_cfg.grad_accum_steps = std::max(1, cli.grad_accum);
        trainer_cfg.output_dir = cli.output_dir;
        trainer_cfg.max_steps = cli.max_steps;
        trainer_cfg.eval_steps = 0;
        trainer_cfg.logging_steps = 1;
        trainer_cfg.warmup_ratio = cli.warmup_ratio;
        trainer_cfg.max_grad_norm = cli.max_grad_norm;
        trainer_cfg.weight_decay = cli.weight_decay;
        trainer_cfg.dump_embedding = cli.dump_embedding;
        trainer_cfg.dump_embedding_step = std::max(1, cli.dump_embedding_step);
        trainer_cfg.dump_embedding_dir = cli.dump_embedding_dir;
        trainer_cfg.pm_interval = cli.pm_interval;
        trainer_cfg.pm_batt_thresh = cli.pm_batt_thresh;
        trainer_cfg.pm_temp_thresh = cli.pm_temp_thresh;
        trainer_cfg.pm_fb_high = cli.pm_fb_high;
        trainer_cfg.pm_fb_low = cli.pm_fb_low;
        trainer_cfg.pm_ft_high = cli.pm_ft_high;
        trainer_cfg.pm_ft_low = cli.pm_ft_low;
        trainer_cfg.pm_manual_batt = cli.pm_manual_batt;
        trainer_cfg.pm_manual_temp = cli.pm_manual_temp;
        trainer_cfg.pm_enable_batt = cli.pm_enable_batt;
        trainer_cfg.pm_enable_temp = cli.pm_enable_temp;
        trainer_cfg.pm_schedule = cli.pm_schedule;

        GemmaLoRATrainer trainer(model, injector, train_data, eval_data, trainer_cfg);
        trainer.train();

        std::cout << "[Save] Writing LoRA adapter..." << std::endl;
        trainer.save_lora(trainer_cfg.output_dir + "/gemma_lora.safetensors");

        std::cout << "Gemma LoRA training completed" << std::endl;
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "\nError: " << e.what() << std::endl;
        return 1;
    }
}
